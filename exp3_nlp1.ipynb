{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc193cb-ad7a-42d5-b183-126fef9a1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc1d17a-b9b2-408f-b142-e7d8350f00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"NLP combines computational linguistics—rule-based modeling of human language—with statistical, machine learning, and deep learning models. Together, these technologies enable computers to process human language in the form of text or voice data and to ‘understand’ its full meaning, complete with the speaker or writer’s intent and sentiment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cfdedb6-c4bc-4e40-a3aa-f4416486600b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'combines', 'computational', 'linguistics—rule-based', 'modeling', 'of', 'human', 'language—with', 'statistical', ',', 'machine', 'learning', ',', 'and', 'deep', 'learning', 'models', '.', 'Together', ',', 'these', 'technologies', 'enable', 'computers', 'to', 'process', 'human', 'language', 'in', 'the', 'form', 'of', 'text', 'or', 'voice', 'data', 'and', 'to', '‘', 'understand', '’', 'its', 'full', 'meaning', ',', 'complete', 'with', 'the', 'speaker', 'or', 'writer', '’', 's', 'intent', 'and', 'sentiment', '.']\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZATION\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a424a4-f4ed-4919-82be-9ace8640e44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'combines', 'computational', 'linguistics—rule-based', 'modeling', 'human', 'language—with', 'statistical', ',', 'machine', 'learning', ',', 'deep', 'learning', 'models', '.', 'Together', ',', 'technologies', 'enable', 'computers', 'process', 'human', 'language', 'form', 'text', 'voice', 'data', '‘', 'understand', '’', 'full', 'meaning', ',', 'complete', 'speaker', 'writer', '’', 'intent', 'sentiment', '.']\n"
     ]
    }
   ],
   "source": [
    "# STOP WORD REMOVAL\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ace3a41-07fc-45ae-b798-ebb9d4469a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'combine', 'computational', 'linguistics—rule-based', 'modeling', 'human', 'language—with', 'statistical', ',', 'machine', 'learning', ',', 'deep', 'learning', 'model', '.', 'Together', ',', 'technology', 'enable', 'computer', 'process', 'human', 'language', 'form', 'text', 'voice', 'data', '‘', 'understand', '’', 'full', 'meaning', ',', 'complete', 'speaker', 'writer', '’', 'intent', 'sentiment', '.']\n"
     ]
    }
   ],
   "source": [
    "# LEMATIZATION\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe40c34-04e4-4d4a-83ea-2dfda4d36a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp', 'combin', 'comput', 'linguistics—rule-bas', 'model', 'human', 'language—with', 'statist', ',', 'machin', 'learn', ',', 'deep', 'learn', 'model', '.', 'togeth', ',', 'technolog', 'enabl', 'comput', 'process', 'human', 'languag', 'form', 'text', 'voic', 'data', '‘', 'understand', '’', 'full', 'mean', ',', 'complet', 'speaker', 'writer', '’', 'intent', 'sentiment', '.']\n"
     ]
    }
   ],
   "source": [
    "# STEMMING\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c436a9-8e70-447d-8f1e-687951219ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
